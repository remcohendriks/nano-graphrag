# Configuration for Qdrant Vector Storage mode
# Tests Qdrant as the vector backend with OpenAI LLM

# Test data configuration
# Use full corpus for thorough testing (comment out to use all data)
TEST_DATA_LINES=1000

# LLM Configuration
LLM_PROVIDER=openai
LLM_MODEL=gpt-5-mini
LLM_MAX_TOKENS=32768
LLM_MAX_CONCURRENT=8
LLM_CACHE_ENABLED=true
LLM_TEMPERATURE=0.0

# Embedding Configuration  
EMBEDDING_PROVIDER=openai
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIMENSION=1536
EMBEDDING_BATCH_SIZE=32
EMBEDDING_MAX_CONCURRENT=8

# Storage Configuration - Using Qdrant for vector storage
STORAGE_VECTOR_BACKEND=qdrant
STORAGE_GRAPH_BACKEND=networkx
STORAGE_KV_BACKEND=json
# Working dir set dynamically by health check script

# Qdrant specific configuration
QDRANT_URL=http://localhost:6333
# QDRANT_API_KEY=your-api-key  # Uncomment for Qdrant Cloud
# QDRANT_COLLECTION_PARAMS={}  # Optional collection params
# Custom namespace prefix for Qdrant collections (uses working dir name if not set)
QDRANT_NAMESPACE_PREFIX=test_qdrant

# Chunking Configuration (tuned for speed)
CHUNKING_STRATEGY=token
# Larger chunks to reduce number of LLM calls
CHUNKING_SIZE=1200
# Standard overlap
CHUNKING_OVERLAP=100
CHUNKING_TOKENIZER=tiktoken
CHUNKING_TOKENIZER_MODEL=gpt-4.1

# Entity Extraction (tuned for speed)
# No gleaning for fastest speed
ENTITY_MAX_GLEANING=0
# Shorter summaries
ENTITY_SUMMARY_MAX_TOKENS=300
ENTITY_STRATEGY=llm

# Graph Clustering (tuned for speed)
GRAPH_CLUSTERING_ALGORITHM=leiden
# Reasonable cluster size for better community detection
GRAPH_MAX_CLUSTER_SIZE=10
GRAPH_CLUSTERING_SEED=3967219502

# Query Configuration
QUERY_ENABLE_LOCAL=true
QUERY_ENABLE_GLOBAL=true
QUERY_ENABLE_NAIVE_RAG=true
QUERY_SIMILARITY_THRESHOLD=0.2