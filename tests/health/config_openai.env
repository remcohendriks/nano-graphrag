# Configuration for OpenAI mode
# Uses gpt-5 models as per CLAUDE.md

# Test data configuration
TEST_DATA_LINES=1000

# LLM Configuration
LLM_PROVIDER=openai
LLM_MODEL=gpt-5-mini
LLM_MAX_TOKENS=32768
LLM_MAX_CONCURRENT=8
LLM_CACHE_ENABLED=true
LLM_TEMPERATURE=0.0

# Embedding Configuration  
EMBEDDING_PROVIDER=openai
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIMENSION=1536
EMBEDDING_BATCH_SIZE=32
EMBEDDING_MAX_CONCURRENT=8

# Storage Configuration
STORAGE_VECTOR_BACKEND=nano
STORAGE_GRAPH_BACKEND=networkx
STORAGE_KV_BACKEND=json
# Working dir set dynamically by health check script

# Chunking Configuration (tuned for speed)
CHUNKING_STRATEGY=token
# Larger chunks to reduce number of LLM calls
CHUNKING_SIZE=1200
# Standard overlap
CHUNKING_OVERLAP=100
CHUNKING_TOKENIZER=tiktoken
CHUNKING_TOKENIZER_MODEL=gpt-4.1

# Entity Extraction (tuned for speed)
# No gleaning for fastest speed
ENTITY_MAX_GLEANING=0
# Shorter summaries
ENTITY_SUMMARY_MAX_TOKENS=300
ENTITY_STRATEGY=llm

# Graph Clustering (tuned for speed)
GRAPH_CLUSTERING_ALGORITHM=leiden
# Reasonable cluster size for better community detection
GRAPH_MAX_CLUSTER_SIZE=10
GRAPH_CLUSTERING_SEED=3967219502

# Query Configuration
QUERY_ENABLE_LOCAL=true
QUERY_ENABLE_GLOBAL=true
QUERY_ENABLE_NAIVE_RAG=true
QUERY_SIMILARITY_THRESHOLD=0.2